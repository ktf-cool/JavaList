# 并发编程挑战



## 一、上下文切换

- 即使是单核处理器也支持多线程执行代码，`CPU`通过给每个线程分配`CPU`时间片来实现这个机制。

> 时间片是`CPU`分配给各个线程的时间，因为时间片非常短，所以`CPU`通过不停地切换线程执行，让我们感觉多个线程是同时执行的，时间片一般是几十毫秒（`ms`）。

- `CPU`通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务。但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再加载这个任务的状态。所以任务从保存到再加载的过程就是一次上下文切换。

> 上下文切换会影响多线程的执行速度。

### 1. 多线程一定快吗

```java
public class ConcurrencyTest {
		private static final long count = 10000l;
		public static void main(String[] args) throws InterruptedException {
				concurrency();
				serial();
		}
		private static void concurrency() throws InterruptedException {
				long start = System.currentTimeMillis();
				Thread thread = new Thread(new Runnable() {
					@Override
					public void run() {
						int a = 0;
						for (long i = 0; i < count; i++) {
							a += 5;
						}
					}
			});
			thread.start();
			int b = 0;
			for (long i = 0; i < count; i++) {
					b--;
			}
			long time = System.currentTimeMillis() - start;
			thread.join();
			System.out.println("concurrency :" + time+"ms,b="+b);
	}
	private static void serial() {
			long start = System.currentTimeMillis();
			int a = 0;
			for (long i = 0; i < count; i++) {
					a += 5;
			}
			int b = 0;
			for (long i = 0; i < count; i++) {
					b--;
		    }
			long time = System.currentTimeMillis() - start;
			System.out.println("serial:" + time+"ms,b="+b+",a="+a);
	}
}
```

> 结果如表所示：

![image](https://github.com/ktf-cool/JavaList/blob/master/images/%E5%B9%B6%E5%8F%91%E6%97%B6%E9%97%B4%E6%B5%8B%E8%AF%95.png)

> 当并发执行累加操作不超过百万次时，速度会比串行执行累加操作要慢。那么，为什么并发执行的速度会比串行慢呢？这是因为线程有创建和上下文切换的开销。

### 2.如何减少上下文切换

- 减少上下文切换的方法有无锁并发编程、`CAS`算法、使用最少线程和使用协程。
  - 无锁并发编程。多线程竞争锁时，会引起上下文切换，所以多线程处理数据时，可以用一些办法来避免使用锁，如将数据的`ID`按照`Hash`算法取模分段，不同的线程处理不同段的数据。
  - `CAS`算法。`Java`的`Atomic`包使用`CAS`算法来更新数据，而不需要加锁。
  - 使用最少线程。避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这样会造成大量线程都处于等待状态。

- 协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。



## 二、死锁

- 锁是个非常有用的工具，运用场景非常多，因为它使用起来非常简单，而且易于理解。但同时它也会带来一些困扰，那就是可能会引起死锁，一旦产生死锁，就会造成系统功能不可用。
- 让我们先来看一段代码，这段代码会引起死锁，使线程`t1`和线程`t2`互相等待对方释放锁。

```java
public class DeadLockDemo {
	privat static String A = "A";
	private static String B = "B";
	public static void main(String[] args) {
		new DeadLockDemo().deadLock();
	}
	private void deadLock() {
		Thread t1 = new Thread(new Runnable() {
				@Override
				publicvoid run() {
					synchronized (A) {
						try { Thread.currentThread().sleep(2000);
						} catch (InterruptedException e) {
							e.printStackTrace();
						}
						synchronized (B) {
							System.out.println("1");
						}
					}
				}
			});
			Thread t2 = new Thread(new Runnable() {
				@Override
				publicvoid run() {
					synchronized (B) {
						synchronized (A) {
							System.out.println("2");
						}
					}
				}
			});
			t1.start();
			t2.start();
	}
}
```

> 这段代码只是演示死锁的场景，在现实中你可能不会写出这样的代码。但是，在一些更为复杂的场景中，你可能会遇到这样的问题，比如`t1`拿到锁之后，因为一些异常情况没有释放锁（死循环）。又或者是`t1`拿到一个数据库锁，释放锁的时候抛出了异常，没释放掉。

- 一旦出现死锁，业务是可感知的，因为不能继续提供服务了，那么只能通过`dump`线程查看到底是哪个线程出现了问题。

- 避免死锁的几个常见方法：
  - 避免一个线程同时获取多个锁。
  - 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。
  - 尝试使用定时锁，使用`lock.tryLock（timeout）`来替代使用内部锁机制。
  - 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况。



## 三、资源限制的挑战

- 资源限制是指在进行并发编程时，程序的执行速度受限于计算机硬件资源或软件资源。
- 例如，服务器的带宽只有`2Mb/s`，某个资源的下载速度是`1Mb/s`每秒，系统启动`10`个线程下载资源，下载速度不会变成`10Mb/s`，所以在进行并发编程时，要考虑这些资源的限制。
  - 硬件资源限制有带宽的上传/下载速度、硬盘读写速度和`CPU`的处理速度。
  - 软件资源限制有数据库的连接数和socket连接数等。

- 在并发编程中，将代码执行速度加快的原则是将代码中串行执行的部分变成并发执行，但是如果将某段串行的代码并发执行，因为受限于资源，仍然在串行执行，这时候程序不仅不会加快执行，反而会更慢，因为增加了上下文切换和资源调度的时间。
  - 例如，之前看到一段程序使用多线程在办公网并发地下载和处理数据时，导致`CPU`利用率达到`100%`，几个小时都不能运行完成任务，后来修改成单线程，一个小时就执行完成了。

- 对于硬件资源限制，可以考虑使用集群并行执行程序。既然单机的资源有限制，那么就让程序在多机上运行。比如使用`ODPS`、`Hadoop`或者自己搭建服务器集群，不同的机器处理不同的数据。可以通过“数据`ID%`机器数”，计算得到一个机器编号，然后由对应编号的机器处理这笔数据。
- 对于软件资源限制，可以考虑使用资源池将资源复用。比如使用连接池将数据库和`Socket`连接复用，或者在调用对方`webservice`接口获取数据时，只建立一个连接。

